\chapter{Trusted Types integration process}
\label{tt_integration_setup}

In this chapter, we describe how the integration process works in general. We have implemented
multiple integrations, some of which are described in this paper. We try to provide an abstract view
of the common properties of integrations based on our experience. This methodology is especially
important for new integration authors as it provides guidelines on how to create a new integration.

Integrating Trusted Types to applications and libraries might seem like a complex task that requires
good knowledge of the project internals. There is a small sample of already implemented
integrations, which shows that the necessary code changes are relatively small
\cite{tt_integration_list}. Based on our experience, the integration does not require the expertise
of the project's inner workings either. This experience is also supported by other integration
authors \cite{tt_web_framework_paper}. Each integration is different, but on a high level they
follow the same principles:

\begin{enumerate}
  \item Locate DOM sinks
  \item Find a workaround for every sink found
  \item Implement and release the integration
\end{enumerate}

\section{Locating DOM sinks}

Locating the sinks in a framework is important for scoping the complexity and the implementation
afterward. This is a hard task since there is no bulletproof way of locating all the sinks in a
codebase, especially due to JavaScript being a dynamic language. Fortunately, there are a few
methods and tools, which can help to catch most of the sinks:

\begin{enumerate}
  \item Static search
  \item Code analyzers
  \item Runtime analysis
\end{enumerate}

\subsection{Static search}

This method is one of the simplest ones. Statically searching for sinks in a codebase produces many
false positives and false negatives. The former are produced for read-only sink usage, the latter
when the project contains sinks that are missed by the static search. This usually happens when the
project uses dynamic property access on an HTML document or element. The output of the static search
is usually cluttered with violations in tests and build tools, which need to be manually excluded
from the search.

Nevertheless, this method is easy to reason about, fast to iterate and the final search results can
provide a good estimate of the integration scope. This works well in practice since there is an
assumption that the project developers are not malicious and do not use code patterns that are
trying to hide or cause an XSS vulnerability.

There is not an actively maintained static search tool for finding DOM sinks. However, it is
relatively easy to build a script, which uses the existing tools such as \emph{grep} with a list
of already known sinks \cite{xss_sink_finder}.

\subsection{Code analyzers}

A special subgroup of static search tools is code analyzers. Code analyzers use the AST of the
project source code to find the DOM sinks. The quality of the output produced proportionally depends
on the quality of the AST information. When the codebase is using TypeScript, the AST information is
generally richer compared to codebases using JavaScript. One can then build and use tools like Tsec
\cite{tsec_github} which uses the compiler to parse the source code and create the AST to ultimately
find the sinks more reliably and produces fewer false positives.

These tools have the advantage that they can be used to maintain Trusted Types compatibility even
after the violations are fixed. For example, they can be run in a CI pipeline or their output can be
leveraged by linters and other language plugin tools and the errors can be shown to the developers
early on and directly in their IDE \cite{tsec_lsp}.

\subsection{Runtime analysis}

While static search through the codebase is fast and locates most of the sinks, it usually does not
find them all. The code analyzers suffer from the same problem. If the project is a library or a
framework intended to be used by other applications, the integration should be thoroughly tested.
The integration author should verify the integration implementation using a real-world application.
This also helps to ensure backward compatibility with older versions.

That said, finding a suitable application to test the Trusted Types integration can be challenging
and it may not be an ideal way to test all edge cases. For example, when implementing an integration
to React, one can find a lot of real-world applications using React, but most of them are already XSS
free so they can be used only to verify if the integration does not break these clients. For this
reason, it is also desirable to create an application from scratch to focus more on the integration
edge cases. Another benefit to creating a custom application is that many violations are found more
easily through runtime analysis. We recommend doing this for all integrations.

The recommendation for application authors is to use the report-only mode of Trusted Types. This
enables gradual migration and allows them to work on application features in parallel.

\section{Finding a workaround for a sink}

In this section, we assume that all the sinks discussed produce Trusted Types violations. Note, that
a sink can produce a Trusted Types violation for a value that is provably secure. For example, this
happens when a constant string is assigned to an \emph{innerHTML} property of a DOM element.
Generally, there are three ways how to resolve a Trusted Types violation produced by a sink:

\begin{enumerate}
  \item Find a safer alternative
  \item Wrap the value in a Trusted Types policy
  \item Ensure user-supplied sink value is immutable
\end{enumerate}

\subsection{Finding a safer alternative}

For some sinks, there exists a safer alternative API that can be used. For example, for non-script
elements, one can use \emph{Element.textContent} instead of \emph{element.innerHTML}. Developers use
\emph{innerHTML} mostly because of legacy reasons since \emph{textContent} is only available in IE
from version 9 \cite{text_content_mdn}. However, the support for this version has ended in January
2016 and the support for the latest IE 11 will end in June 2022 in favor of Microsoft Edge. Due to
these reasons, applications are encouraged to avoid this trick and drop the support for IE or at
least IE 9.

Another use case \emph{innerHTML} property is to assign a constant string representing the HTML
markup. This is done for convenience to create a small chunk of HTML that is displayed on a page.
The alternative is to create DOM nodes dynamically and only append the generated elements to the
target element as a child.

Unfortunately, these workarounds can be applied only when there is a safer API alternative, which is
often not the case and this solution is not applicable.

\subsection{Wrapping the value in a policy}

When there is no way to avoid using the sink and the value is trusted, developers can use a Trusted
Types policy to promote a trusted value to a Trusted Types instance. One should apply a policy as
soon as the value can be trusted. This usually means the place where the value is created. For
example, the author should promote a value to Trusted Type immediately after sanitization or
escaping. This way the unforgeability of Trusted Types can preserve the "trust" independently of how
the value flows through code until it reaches the sink.

In the future, Trusted Types API might provide support for constructing trusted values from string
constants via template literals without using a policy, but this is not yet supported
\cite{tt_from_literal_method}.

After the value is converted to a Trusted Types instance, the application needs to make sure the
value is not altered before it reaches the sink and no string functions are attempted
(\ref{tt_integration_ensure_tt_not_altered}).

\subsection{Ensuring the sink value is immutable}
\label{tt_integration_ensure_tt_not_altered}

As we mentioned, Trusted Types instances are immutable and unforgeable values. Previously, the DOM
sinks accepted string values so the application might have used string operations on the value, such
as calling a common string function. Since the new values do not have string methods defined, any
call attempt results in an error. Another problem is stringification which converts a Trusted Types
instance to a regular string, dropping the trust guarantees provided by Trusted Types, which then
throws an error when the value is passed to the sink.

The integration author needs to refactor the code to prevent modifying the trusted values to
preserve the trust guarantees secured by Trusted Types.

\section{Implementing and releasing the integration}

Implementing the integration and releasing a new version of the application or library is
undoubtedly an important part of the Trusted Types integration process. However, this can take a
long time for multiple reasons. Some of them are described in separate sections below:

\begin{enumerate}
  \item Reasoning about the integration
  \item Trusted Types compatibility in dependencies
  \item Integration complexity
\end{enumerate}

\subsection{Reasoning about the integration}
\label{sub:reason_about_integration}

Proving that the integration is correct means to determining if all sinks have been located and
properly addressed. This is generally infeasible or impossible to prove. Projects usually look at
patches empirically. If the integration looks correct and is properly tested then it is safe to
assume that the integration is indeed correct. This is especially true when the integration is
tested by large-scale organizations by a lot of services.

That being said, Trusted Types enforcement is a breaking change for projects. Libraries that can
conditionally create Trusted Types should make this change opt-in. If the integration is turned on
by default when Trusted Types are available in the browser, the library is risking breaking the
existing applications since they might expect the values to be string instances
\cite{dom_purify_breakage}. When an opt-in configuration is not possible, the library should release
the integration as a breaking change with a new major version. The alternative is to put Trusted
Types integration behind a feature flag. The downside is that this can hurt the adoption
\cite{react_tt_feature_flag}.

\subsection{Compatibility of dependencies}
\label{sub:tt_compatibility_in_deps}

Implementing the integration in large-scale projects, which consist of many dependencies and vendors
can bring a lot of overhead because to be fully Trusted Types compliant developers must ensure that
all of the third-party code is Trusted Types complaint as well.

When there is non-compliant dependency, one has multiple options:

\begin{itemize}
  \item Implement the integration for the dependency -- This option leads to more integrations being
        needed. Also, these dependencies might be reluctant to adopt Trusted Types and accept the
        integration.
  \item Find an alternative dependency -- This option is often impossible because a viable
        alternative might not exist. Also, replacing a dependency with an alternative increases the
        integration effort, and projects might not want to migrate to an alternative dependency only
        because of Trusted Types compliance.
  \item Use Trusted Types default policy -- This option should only be used by applications and
        implementing the default policy can be difficult. Moreover, the default policy brings a
        cost, the application is not fully Trusted Types compliant, and using the default policy can
        reduce application performance.
\end{itemize}

\subsection{Integration complexity}
\label{sub:trust_integration_author}

The difficulty of Trusted Types integrations can vary. Some integrations may require minimal effort
or no code changes at all. Some integrations can be more complex, for example, the Angular
integration \cite{tt_web_framework_paper}.

Especially in the open-source ecosystem, the author of the integration might be an external
contributor who has limited knowledge about the project. Our experience suggests, that developers
can implement integrations despite not being familiar with the project internals. That being said,
the project might be reluctant to merge the integration due to the introduced complexity.
