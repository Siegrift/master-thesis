\chapter{Trusted Types integration}
\label{tt_integration_setup}

Integrating Trusted Types to target applications and libraries is a might seem as complex task that
requires good knowledge of the target inner workings. There is a small sample of already implemented
integrations, which show that the necessary code changes are relatively small
\cite{tt_integration_list}. Based on our experience, the integration does not require an exprteese
of the projects inner workings. This experience is also supported by other integration authors
\cite{tt_web_framework_paper}. Each integration is different, but on a high level they follow the
same steps:

\begin{enumerate}
  \item Locate all of the DOM sinks
  \item Find the most suitable workaround for every sink found
  \item Implement the integration and release a new version of the target
\end{enumerate}

\section{Locate all of the DOM sinks}

Locating the sinks of the integration target is important for scoping the integration effort and the
implementation afterwards. This task is complex since there is no bulletproof way of locating all of
the sinks in a codebase. This is because JavaScript is a dynamic language and it is possible to
access and set the sink values dynamically using the property element access.

Fortunately, there are a few methods and tools, which can help to catch most of the sinks:

\begin{enumerate}
  \item Static search through the codebase
  \item Static code analyzers
  \item Using the target in an real world application
\end{enumerate}

\subsection{Static search through the codebase}

This method is the simplest one and arguably the least effective. Statically searching for sinks
throughout the codebase produces many false positives and false negatives. The former are produced
for read only sink usage, the latter when actual sinks are missed due to implementation limitations.
The output of the static search is usually cluttered with less important violations in tests and
built tools, which you need to manually exclude from the search.

Nevertheless, this method is easy to reason about, fast to iterate and the final search results can
provide a good estimate of the integration scope. This works well in practice since there is an
assumption that the target source code is not malicious and doesn't actively use code patterns which
are trying to hide or cause an XSS vulnerability.

There is not an actively maintained static search tool for finding DOM sinks. However, it is
relatively easy to build a script, which uses the existing tools such as \textit{grep} with a list
of already known sinks \cite{xss_sink_finder}.

\subsection{Static code analyzers}

A better approach at searching for the DOM sinks statically, is to search through the AST of the
code. The quality of the output produced depends on the quality of the AST information. When the
codebase is using TypeScript, the AST information is generally richer compared to codebases using
JavaScript. One can then build and use tools like Tsec \cite{tsec_github} which uses the compiler to
parse the source code and create the AST to ultimately find the sinks in a more reliable manner and
produces less false positives.

These tools have an advantage that they can be used to maintain the Trusted Types compatibility even
after the violations are fixed. For example, they can be run in CI pipeline or their output can be
leveraged by linters and other language plugin tools and the errors can be shown to the developers
directly in their IDE \cite{tsec_lsp}.

\subsection{Using the target in a real world application}

While static search through the codebase is fast and locates most of the sinks, it usually doesn't
catch them all. The author of the integration should verify the integration on the applications
using the target as a dependency. Also, having good test coverage in the application code greatly
increases the chance that the integration is implemented correctly.

That said, finding a suitable application might be challenging and it may not be an ideal way to
test all edge cases. For example, when implementing an integration to React, one can find lot of
real world applications using React, but most of them are already XSS free so you can only verify if
the integration doesn't break these clients.

One recommendation for the clients are to use the the report only mode of Trusted Types CSP. This
allows applications to migrate their code gradually and allows them to focus on application
features.

Library authors need to test how the integration works when used with applications that uses the
DOM sinks and now has to produce Trusted Types values. These are done best by creating an
application from scratch by the integration author.

\section{Find the most suitable workaround for every sink found}

TODO: write me

\section{Implementing the integration and releasing a new version of the target}

Implementing the integration and releasing a new version of the target is undoubtedly an important part
of Trusted Types integration. However, this can take long time for multiple reasons, which are
described in separate sections:

\begin{enumerate}
  \item Reasoning about the integration
  \item Trusted Types compatibility in dependencies
  \item Knowledge required for the integration author
\end{enumerate}

\subsection{Reasoning about the integration}
\label{sub:reason_about_integration}

Proving that the integration is correct means to determine if all sinks have been located and
properly addressed. This is generally infeasible or impossible to determine. Project usually look at
patches empirically. If the integration looks correct and is properly tested then it is safe to
assume that the integration is correct. This is especially true when the integration is tested by
large scale organizations by lot of services.

That being said, Trusted Types enforcement is a breaking change and project should make this change
opt-in or release a new version with breaking changes \cite{dom_purify_major_version}. If the
integration is turned on by default when Trusted Types are available in the browser, the target is
risking breaking existing applications \cite{dom_purify_breakage}.

Releasing an opt-in change might be problematic if the target is not configurable. This can result
in the integration being put behind a feature flag which hurts the adoption
\cite{react_tt_feature_flag}.

\subsection{Trusted Types compatibility in dependencies}
\label{sub:tt_compatibility_in_deps}

Implementing the integration in large projects, which consists of many dependencies can bring a lot
of overhead, because to be fully Trusted Types compliant one must ensure that all of the
dependencies are Trusted Types complaint as well.

When there is non compliant dependency, one has multiple options:

\begin{itemize}
  \item Implement the integration for the dependency - This option leads to recursive integrations
        and has all the problems already mentioned and can possible lead to many more integrations.
  \item Find an alternative dependency - This option is often impossible as a viable alternative
        might not exist and projects might not want to use an alternative only because of Trusted
        Types compliance.
  \item Use Trusted Types default policy - This option should only be used by end applications and
        is more complex. The application is not fully Trusted Types compliant and it can also lead
        to a reduced performance.
\end{itemize}

\subsection{Knowledge required for the integration author}
\label{sub:trust_integration_author}

The integration author can neither be a security engineer familiar with Trusted Types and neither a
part of the engineering team of the target familiar with the target code. This means that the author
might not be fully familiar with both of the technologies and the respective teams, which can result
in both:

\begin{itemize}
  \item Increased propability of a bug in implementation
  \item Harder and longer review, since the reviewers might also lack the information about Trusted
        Types or simply ignore the PR due to other priorities
\end{itemize}
